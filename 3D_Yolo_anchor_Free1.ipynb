{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Training\n",
      "pred_class shape: torch.Size([1, 1, 17, 17, 17])\n",
      "true_class shape: torch.Size([1, 1, 17, 17, 17])\n",
      "Epoch [1/2], Batch [1], Loss: 2.0201175212860107\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print(\"starting Training\")\n",
    "# Define the 3D Basic Block\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Define the 3D Basic Block\n",
    "class FFCM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(FFCM, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels // 2, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.conv2 = nn.Conv3d(out_channels // 2, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        \n",
    "        # Batch Normalization\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels // 2)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        \n",
    "        # Activation\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        # Apply second convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "class BasicBlock3D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)  # Use 'out' instead of 'x'\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define the 3D ResNet model\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1):\n",
    "        super(ResNet3D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.ffcm = FFCM(1, 64)\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.conv = nn.Conv3d(512 * block.expansion, (7 + num_classes), kernel_size=1, stride=1, padding=2)\n",
    "        self.detect = Detect(num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ffcm(x)\n",
    "      #  x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        detections, predictions = self.detect(x)\n",
    "        return detections, predictions\n",
    "\n",
    "# Define the Detect and Loss classes\n",
    "class Detect(nn.Module):\n",
    "    def __init__(self, num_classes, conf_threshold=0.5, nms_threshold=0.4):\n",
    "        super(Detect, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "\n",
    "    def forward(self, predictions):\n",
    "        batch_size, _, d, h, w = predictions.shape\n",
    "        predictions = predictions.view(batch_size, -1, self.num_classes + 7, d, h, w)\n",
    "        \n",
    "        # Calculate the coordinates and dimensions\n",
    "        x_min = predictions[:, :, 0, :, :, :]\n",
    "        y_min = predictions[:, :, 1, :, :, :]\n",
    "        z_min = predictions[:, :, 2, :, :, :]\n",
    "        x_max = predictions[:, :, 3, :, :, :]\n",
    "        y_max = predictions[:, :, 4, :, :, :]\n",
    "        z_max = predictions[:, :, 5, :, :, :]\n",
    "        obj_conf = torch.sigmoid(predictions[:, :, 6, :, :, :])\n",
    "        class_conf, class_pred = torch.max(predictions[:, :, 7:, :, :, :], dim=2)\n",
    "\n",
    "        # Filter out low confidence objectness predictions\n",
    "        mask = obj_conf > self.conf_threshold\n",
    "        detections = []\n",
    "        for batch_idx in range(batch_size):\n",
    "            boxes = []\n",
    "            scores = []\n",
    "            for class_idx in range(self.num_classes):\n",
    "                class_mask = mask[batch_idx, :, :, :, :] & (class_pred[batch_idx, :, :, :, :] == class_idx)\n",
    "                if class_mask.sum() == 0:\n",
    "                    continue\n",
    "                x_min_class = x_min[batch_idx, :, :, :][class_mask]\n",
    "                y_min_class = y_min[batch_idx, :, :, :][class_mask]\n",
    "                z_min_class = z_min[batch_idx, :, :, :][class_mask]\n",
    "                x_max_class = x_max[batch_idx, :, :, :][class_mask]\n",
    "                y_max_class = y_max[batch_idx, :, :, :][class_mask]\n",
    "                z_max_class = z_max[batch_idx, :, :, :][class_mask]\n",
    "                obj_conf_class = obj_conf[batch_idx, :, :, :][class_mask]\n",
    "                class_conf_class = class_conf[batch_idx, :, :, :][class_mask]\n",
    "                scores_class = obj_conf_class * class_conf_class\n",
    "\n",
    "                boxes_class = torch.stack((x_min_class, y_min_class, z_min_class, x_max_class, y_max_class, z_max_class), dim=-1)\n",
    "                keep = custom_3d_nms(boxes_class, scores_class, self.nms_threshold)\n",
    "\n",
    "                if len(keep) > 0:\n",
    "                    boxes.append(boxes_class[keep])\n",
    "                    scores.append(scores_class[keep])\n",
    "\n",
    "            if len(boxes) > 0:\n",
    "                boxes = torch.cat(boxes, dim=0)\n",
    "                scores = torch.cat(scores, dim=0)\n",
    "                detections.append((boxes, scores))\n",
    "            else:\n",
    "                detections.append((torch.zeros((0, 6)), torch.zeros((0,))))\n",
    "\n",
    "        return detections, predictions.view(batch_size, -1, d, h, w)\n",
    "\n",
    "def custom_3d_nms(boxes, scores, threshold):\n",
    "    if boxes.size(0) == 0:\n",
    "        return torch.empty(0, dtype=torch.int64, device=boxes.device)\n",
    "\n",
    "    # Sort scores in descending order\n",
    "    _, idxs = scores.sort(descending=True)\n",
    "    boxes = boxes[idxs]\n",
    "    scores = scores[idxs]\n",
    "\n",
    "    keep = []\n",
    "    max_iterations = 1000  # Set a maximum number of iterations to prevent infinite loops\n",
    "    iteration = 0\n",
    "\n",
    "    while boxes.size(0) > 0:\n",
    "        pick = boxes.new_tensor([0], dtype=torch.long)\n",
    "        keep.append(idxs[pick].item())\n",
    "\n",
    "        if boxes.size(0) == 1:\n",
    "            break\n",
    "\n",
    "        iou = compute_3d_iou(boxes[pick].unsqueeze(0), boxes)\n",
    "        mask = (iou <= threshold).squeeze(0)\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            break  # No boxes left after NMS\n",
    "\n",
    "        boxes = boxes[mask]\n",
    "        scores = scores[mask]\n",
    "        idxs = idxs[mask]\n",
    "\n",
    "        iteration += 1\n",
    "   #     print(f\"Remaining boxes: {boxes.size(0)}, Iteration: {iteration}\")  # Debugging print statement\n",
    "\n",
    "        if iteration >= max_iterations:\n",
    "       #     print(\"Reached maximum iterations in NMS, breaking out to prevent infinite loop.\")\n",
    "            break\n",
    "\n",
    "    return torch.tensor(keep, dtype=torch.int64, device=boxes.device)\n",
    "\n",
    "def compute_3d_iou(box1, boxes):\n",
    "    if box1.dim() == 1:\n",
    "        box1 = box1.unsqueeze(0)\n",
    "    elif box1.dim() == 3:\n",
    "        box1 = box1.squeeze(0)\n",
    "\n",
    "    inter_xmin = torch.max(box1[:, 0].unsqueeze(1), boxes[:, 0])\n",
    "    inter_ymin = torch.max(box1[:, 1].unsqueeze(1), boxes[:, 1])\n",
    "    inter_zmin = torch.max(box1[:, 2].unsqueeze(1), boxes[:, 2])\n",
    "    inter_xmax = torch.min(box1[:, 3].unsqueeze(1), boxes[:, 3])\n",
    "    inter_ymax = torch.min(box1[:, 4].unsqueeze(1), boxes[:, 4])\n",
    "    inter_zmax = torch.min(box1[:, 5].unsqueeze(1), boxes[:, 5])\n",
    "\n",
    "    inter_volume = torch.clamp(inter_xmax - inter_xmin, min=0) * torch.clamp(inter_ymax - inter_ymin, min=0) * torch.clamp(inter_zmax - inter_zmin, min=0)\n",
    "    box1_volume = (box1[:, 3] - box1[:, 0]) * (box1[:, 4] - box1[:, 1]) * (box1[:, 5] - box1[:, 2])\n",
    "    boxes_volume = (boxes[:, 3] - boxes[:, 0]) * (boxes[:, 4] - boxes[:, 1]) * (boxes[:, 5] - boxes[:, 2])\n",
    "\n",
    "    union_volume = box1_volume.unsqueeze(1) + boxes_volume - inter_volume\n",
    "    iou = inter_volume / union_volume\n",
    "\n",
    "    return iou\n",
    "\n",
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, num_classes, obj_weight=1.0, noobj_weight=1.0, class_weight=1.0):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.obj_weight = obj_weight\n",
    "        self.noobj_weight = noobj_weight\n",
    "        self.class_weight = class_weight\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Slicing predictions to get individual components\n",
    "        pred_bboxes = predictions[:, :6, ...]  # Assuming first 6 channels are bbox predictions\n",
    "        pred_obj_conf = predictions[:, 6, ...]  # Assuming 7th channel is objectness confidence\n",
    "        pred_class = predictions[:, 7:7+self.num_classes, ...]  # Following channels are class predictions\n",
    "\n",
    "        # Slicing targets to get individual components\n",
    "        true_bboxes = targets[:, :6, ...]\n",
    "        true_obj_conf = targets[:, 6, ...]\n",
    "        true_class = targets[:, 7:7+self.num_classes, ...]  # Assuming one-hot encoded class targets\n",
    "\n",
    "        # Debug prints for shapes\n",
    "        print(\"pred_class shape:\", pred_class.shape)\n",
    "        print(\"true_class shape:\", true_class.shape)\n",
    "\n",
    "        # Calculate MSE loss for bounding box predictions\n",
    "        box_loss = self.mse_loss(pred_bboxes, true_bboxes)\n",
    "\n",
    "        # Calculate BCE loss for objectness confidence\n",
    "        obj_loss = self.bce_loss(pred_obj_conf, true_obj_conf)\n",
    "\n",
    "        # Calculate BCE loss for class predictions\n",
    "        class_loss = self.bce_loss(pred_class, true_class)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = box_loss + self.obj_weight * obj_loss + self.noobj_weight * (1 - obj_loss) + self.class_weight * class_loss\n",
    "        return total_loss\n",
    "# Example model and loss initialization\n",
    "# Example model and loss initialization\n",
    "model = ResNet3D(BasicBlock3D, [2, 2, 2, 2], num_classes=1)  # Adjust num_classes based on your actual setup\n",
    "loss_fn = YoloLoss(num_classes=101)  # Adjust num_classes here as well\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 2\n",
    "\n",
    "# Example training data loader (replace with your actual data loader)\n",
    "# This is a placeholder; you should use your actual DataLoader providing (input_data, targets) pairs\n",
    "# train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# For demonstration, using dummy data\n",
    "input_data = torch.randn((1, 1, 204, 204, 204))  # Example input with 1 channel\n",
    "targets = torch.zeros((1, 8, 17, 17, 17))  # Adjust target size to match predictions\n",
    "targets[0, :6, 5, 5, 5] = 0.5  # Example bounding box target\n",
    "targets[0, 6, 5, 5,5] = 1  # Object confidence target\n",
    "targets[0, 7:7+1, 5, 5, 5] = 1  # Class target \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # Example loop over data (replace with your actual data loader loop)\n",
    "    for batch_idx in range(1):  # replace with 'for input_data, targets in train_loader:'\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        detections, predictions = model(input_data)\n",
    "\n",
    "        # Apply sigmoid to the predictions\n",
    "        predictions_sigmoid = torch.sigmoid(predictions)\n",
    "\n",
    "        # Calculate loss using the custom loss function\n",
    "        loss = loss_fn(predictions_sigmoid, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss for this batch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}], Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3104e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#100140': [[101.5, 85.0, 97.0, 9, 16, 16]], '#100151': [[120.0, 89.0, 87.5, 30, 12, 19]], '#100152': [[106.5, 79.5, 127.0, 11, 13, 14]], '#100171': [[64.0, 71.5, 107.0, 26, 13, 18]], '#100205': [[137.5, 70.0, 106.5, 21, 24, 29]], '#100218': [[121.0, 62.0, 112.0, 24, 12, 14]], '#100231': [[73.0, 96.5, 83.0, 18, 13, 14]], '#100234': [[82.5, 86.0, 86.5, 23, 12, 11]], '#100242': [[50.5, 87.5, 114.0, 21, 21, 22]], '#100277': [[122.5, 87.0, 130.5, 19, 20, 15]], '#100305': [[81.0, 86.0, 88.0, 18, 14, 16]], '#100316': [[182.5, 82.5, 111.0, 13, 13, 12]], '#100324': [[81.5, 93.0, 85.0, 19, 22, 28]], '#100326': [[99.5, 85.5, 109.5, 11, 19, 17]], '#100394': [[167.5, 93.0, 103.0, 11, 12, 12]], '#100428': [[120.5, 83.0, 116.5, 11, 10, 13]], '#100455': [[52.5, 82.0, 107.5, 13, 14, 19]], '#100460': [[186.0, 95.0, 111.0, 16, 12, 16]], '#100517': [[158.0, 86.0, 102.0, 32, 18, 20]], '#100536': [[32.5, 80.5, 95.5, 9, 27, 15]], '#100556': [[166.0, 87.5, 103.0, 14, 9, 18]], '#100601': [[147.0, 64.5, 142.5, 22, 13, 13]], '#100643': [[17.0, 79.0, 102.0, 16, 14, 14]], '#100649': [[97.5, 84.0, 102.5, 13, 14, 17]], '#100660': [[75.0, 84.5, 87.5, 16, 15, 13]], '#100673': [[134.5, 76.5, 103.0, 27, 19, 30]], '#100680': [[80.0, 80.0, 90.0, 24, 20, 24]], '#100700': [[98.5, 42.0, 110.5, 27, 28, 25]], '#100723': [[83.5, 92.0, 82.5, 27, 22, 33]], '#100739': [[17.0, 89.5, 108.0, 14, 15, 14]], '#100818': [[155.5, 85.0, 114.5, 23, 24, 17]], '#100873': [[110.5, 85.0, 95.0, 13, 20, 16]], '#100880': [[121.5, 66.0, 100.0, 19, 16, 12]], '#100915': [[112.0, 88.0, 78.0, 14, 16, 16]], '#100988': [[39.5, 95.5, 92.5, 19, 17, 17]], '#101026': [[53.5, 72.0, 113.0, 13, 18, 20]], '#101043': [[160.5, 86.0, 113.0, 7, 10, 18]], '#101054': [[28.5, 111.0, 97.5, 11, 12, 13]], '#101085': [[74.5, 96.5, 94.0, 19, 17, 18]], '#101118': [[120.0, 78.0, 93.5, 22, 12, 17]], '#101122': [[128.0, 66.5, 104.5, 12, 15, 13]], '#101140': [[125.0, 70.0, 97.5, 12, 14, 13]], '#101148': [[106.5, 55.5, 103.5, 9, 15, 17]], '#101157': [[46.5, 86.5, 89.0, 19, 9, 14]], '#101158': [[169.5, 78.0, 112.0, 17, 12, 14]], '#101194': [[184.0, 78.5, 108.0, 20, 13, 16]], '#101220': [[130.0, 68.0, 106.5, 12, 14, 15]], '#101234': [[120.5, 86.0, 91.0, 25, 20, 14]], '#101263': [[121.5, 87.0, 96.0, 17, 14, 32]], '#101272': [[19.5, 82.0, 100.0, 15, 8, 10]], '#101298': [[155.0, 96.0, 116.0, 12, 14, 14]], '#101302': [[41.5, 71.5, 104.5, 11, 15, 17]], '#101309': [[98.0, 78.0, 112.0, 14, 12, 10]], '#101331': [[97.5, 82.5, 106.5, 9, 13, 15]], '#101365': [[83.5, 82.0, 122.0, 17, 16, 16]], '#101393': [[182.5, 91.0, 106.0, 13, 26, 20]], '#101493': [[103.0, 41.0, 110.0, 24, 20, 20]], '#101495': [[151.0, 74.5, 115.5, 10, 19, 13]], '#101508': [[40.5, 91.5, 104.5, 13, 19, 13]], '#101516': [[12.0, 100.0, 130.0, 10, 18, 12]], '#101562': [[23.5, 88.5, 109.0, 17, 17, 14]], '#101601': [[171.0, 91.5, 100.5, 14, 15, 17]], '#101675': [[80.5, 84.0, 86.5, 19, 14, 17]], '#101735': [[42.0, 74.0, 121.0, 18, 12, 10]], '#101782': [[123.5, 83.5, 90.0, 17, 15, 12]], '#101842': [[42.0, 76.5, 93.0, 20, 23, 20]], '#101885': [[100.5, 85.0, 118.5, 13, 24, 23]], '#101892': [[145.0, 75.0, 112.5, 16, 12, 13]], '#101990': [[118.5, 82.5, 81.5, 35, 15, 19]], '#101991': [[106.0, 90.5, 113.0, 16, 15, 16]], '#101995': [[121.0, 72.0, 100.5, 14, 16, 11]], '#101998': [[120.0, 83.5, 103.0, 26, 17, 16]], '#102024': [[75.5, 64.5, 103.5, 19, 13, 21]], '#102084': [[48.0, 88.5, 98.0, 20, 25, 12]], '#102141': [[102.0, 86.5, 116.5, 12, 15, 13]], '#102158': [[157.5, 87.0, 108.0, 17, 16, 18]], '#102200': [[116.0, 92.0, 88.5, 30, 20, 33]], '#102201': [[117.5, 85.0, 96.0, 23, 16, 12]], '#102202': [[102.5, 80.0, 108.0, 15, 18, 10]], '#102228': [[156.0, 86.5, 105.5, 14, 9, 13]], '#102283': [[175.5, 85.0, 98.0, 13, 18, 16]], '#102333': [[114.0, 92.0, 100.0, 20, 20, 20]], '#102348': [[78.0, 83.5, 96.5, 14, 19, 13]], '#102391': [[128.5, 74.5, 108.0, 21, 17, 16]], '#102418': [[126.5, 78.5, 94.5, 19, 25, 17]], '#102427': [[78.5, 93.5, 89.5, 21, 13, 17]], '#102442': [[75.0, 73.5, 100.0, 16, 13, 16]], '#102455': [[152.0, 77.0, 92.5, 16, 12, 17]], '#102496': [[170.5, 82.0, 108.0, 21, 16, 16]], '#102564': [[127.5, 80.5, 113.5, 23, 21, 15]], '#102601': [[96.0, 88.5, 98.5, 16, 15, 11]], '#102609': [[31.0, 89.0, 104.5, 22, 18, 21]], '#102638': [[50.0, 78.0, 121.0, 20, 16, 18]], '#102693': [[167.0, 90.0, 83.5, -84, 16, 17]], '#102720': [[29.0, 93.0, 97.5, 14, 14, 11]], '#102761': [[76.5, 87.0, 89.0, 17, 14, 18]], '#102764': [[81.5, 82.0, 91.5, 19, 20, 11]], '#102797': [[79.5, 94.0, 91.0, 13, 16, 14]], '#102835': [[167.5, 97.0, 94.5, 21, 14, 13]], '#102840': [[120.0, 88.0, 86.0, 18, 12, 16]], '#102886': [[45.0, 82.5, 102.0, 8, 23, 10]], '#102935': [[152.0, 81.0, 112.0, 18, 20, 16]], '#102959': [[75.5, 85.5, 94.5, 19, 15, 9]], '#102974': [[118.5, 85.5, 80.5, 17, 19, 19]]}\n"
     ]
    }
   ],
   "source": [
    "def convert_bboxes(bboxes):\n",
    "    # Check if bboxes is a list of bounding boxes\n",
    "    if isinstance(bboxes[0][0], list):\n",
    "        # Convert each bounding box in the list\n",
    "        return [convert_bboxes(bbox) for bbox in bboxes]\n",
    "    else:\n",
    "        # Convert a single bounding box\n",
    "        x_min, x_max = bboxes[0]\n",
    "        y_min, y_max = bboxes[1]\n",
    "        z_min, z_max = bboxes[2]\n",
    "\n",
    "        x_center = (x_min + x_max) / 2\n",
    "        y_center = (y_min + y_max) / 2\n",
    "        z_center = (z_min + z_max) / 2\n",
    "\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        depth = z_max - z_min\n",
    "\n",
    "        return [x_center, y_center, z_center, width, height, depth]\n",
    "# Example usage\n",
    "bounding_boxes_with_comments = {\n",
    "    \"#100140\": [[[97, 106], [77, 93], [89, 105]]],\n",
    "    \"#100151\": [[[105, 135], [83, 95], [78, 97]]],\n",
    "    \"#100152\": [[[101, 112], [73, 86], [120, 134]]],\n",
    "    \"#100171\": [[[51, 77], [65, 78], [98, 116]]],\n",
    "    \"#100205\": [[[127, 148], [58, 82], [92, 121]]],\n",
    "    \"#100218\": [[[109, 133], [56, 68], [105, 119]]],\n",
    "    \"#100231\": [[[64, 82], [90, 103], [76, 90]]],\n",
    "    \"#100234\": [[[71, 94], [80, 92], [81, 92]]],\n",
    "    \"#100242\": [[[40, 61], [77, 98], [103, 125]]],\n",
    "    \"#100277\": [[[113, 132], [77, 97], [123, 138]]],\n",
    "    \"#100305\": [[[72, 90], [79, 93], [80, 96]]],\n",
    "    \"#100316\": [[[176, 189], [76, 89], [105, 117]]],\n",
    "    \"#100324\": [[[72, 91], [82, 104], [71, 99]]],\n",
    "    \"#100326\": [[[94, 105], [76, 95], [101, 118]]],\n",
    "    \"#100394\": [[[162, 173], [87, 99], [97, 109]]],\n",
    "   # \"#100248\": [[[115, 129], [76, 94], [110, 124]]],\n",
    "    \"#100428\": [[[115,126],[78,88],[110,123]]],\n",
    "    \"#100455\": [[[46, 59], [75, 89], [98, 117]]],\n",
    "    \"#100460\": [[[178, 194], [89, 101], [103, 119]]],\n",
    "    \"#100517\": [[[142, 174], [77, 95], [92, 112]]],\n",
    "    \"#100536\": [[[28, 37], [67, 94], [88, 103]]],\n",
    "    \"#100556\": [[[159, 173], [83, 92], [94, 112]]],\n",
    "    \"#100601\": [[[136, 158], [58, 71], [136, 149]]],\n",
    "    \"#100643\": [[[9, 25], [72, 86], [95, 109]]],\n",
    "    \"#100649\": [[[91, 104], [77, 91], [94, 111]]],\n",
    "    \"#100660\": [[[67, 83], [77, 92], [81, 94]]],\n",
    "    \"#100673\": [[[121, 148], [67, 86], [88, 118]]],\n",
    "    \"#100680\": [[[68, 92], [70, 90], [78, 102]]],\n",
    "    \"#100700\": [[[85, 112], [28, 56], [98, 123]]],\n",
    "    \"#100723\": [[[70, 97], [81, 103], [66, 99]]],\n",
    "    \"#100739\": [[[10, 24], [82, 97], [101, 115]]],\n",
    "    \"#100818\": [[[144, 167], [73, 97], [106, 123]]],\n",
    "    \"#100873\": [[[104, 117], [75, 95], [87, 103]]],\n",
    "    \"#100880\": [[[112, 131], [58, 74], [94, 106]]],\n",
    "    \"#100915\": [[[105, 119], [80, 96], [70, 86]]],\n",
    "    \"#100988\": [[[30, 49], [87, 104], [84, 101]]],\n",
    "    \"#101026\": [[[47, 60], [63, 81], [103, 123]]],\n",
    "    \"#101043\": [[[157, 164], [81, 91], [104, 122]]],\n",
    "    \"#101054\": [[[23, 34], [105, 117], [91, 104]]],\n",
    "    \"#101085\": [[[65, 84], [88, 105], [85, 103]]],\n",
    "    \"#101118\": [[[109, 131], [72, 84], [85, 102]]],\n",
    "    \"#101122\": [[[122, 134], [59, 74], [98, 111]]],\n",
    "    \"#101140\": [[[119, 131], [63, 77], [91, 104]]],\n",
    "    \"#101148\": [[[102, 111], [48, 63], [95, 112]]],\n",
    "    \"#101157\": [[[37, 56], [82, 91], [82, 96]]],\n",
    "    \"#101158\": [[[161, 178], [72, 84], [105, 119]]],\n",
    "    \"#101194\": [[[174, 194], [72, 85], [100, 116]]],\n",
    "    \"#101220\": [[[124, 136], [61, 75], [99, 114]]],\n",
    "    \"#101234\": [[[108, 133], [76, 96], [84, 98]]],\n",
    "    \"#101263\": [[[113, 130], [80, 94], [80, 112]]],\n",
    "    \"#101272\": [[[12, 27], [78, 86], [95, 105]]],\n",
    " #   \"#101288\": [[[35, 48], [86, 103], [90, 104]],[[142,154], [66,78], [100,113]]],\n",
    "    \"#101298\": [[[149, 161], [89, 103], [109, 123]]],\n",
    "    \"#101302\": [[[36, 47], [64, 79], [96, 113]]],\n",
    "    \"#101309\": [[[91, 105], [72, 84], [107, 117]]],\n",
    "    \"#101331\": [[[93, 102], [76, 89], [99, 114]]],\n",
    "    \"#101365\": [[[75, 92], [74, 90], [114, 130]]],\n",
    "    \"#101393\": [[[176, 189], [78, 104], [96, 116]]],\n",
    " #   \"#101426\": [[[12, 23], [65, 90], [88, 98]],[[106,115],[45,57],[104,115]]],  \n",
    "    \"#101493\": [[[91, 115], [31, 51], [100, 120]]],\n",
    "    \"#101495\": [[[146, 156], [65, 84], [109, 122]]],\n",
    "    \"#101508\": [[[34, 47], [82, 101], [98, 111]]],\n",
    "    \"#101516\": [[[7, 17], [91, 109], [124, 136]]],\n",
    "    \"#101562\": [[[15, 32], [80, 97], [102, 116]]],\n",
    "    \"#101601\": [[[164, 178], [84, 99], [92, 109]]],\n",
    "    \"#101675\": [[[71, 90], [77, 91], [78, 95]]],\n",
    "    \"#101735\": [[[33, 51], [68, 80],[116,126]]],\n",
    "    \"#101782\": [[[115, 132], [76, 91], [84, 96]]],\n",
    "    \"#101842\": [[[32, 52], [65, 88], [83, 103]]],\n",
    "    \"#101885\": [[[94, 107], [73, 97], [107, 130]]],\n",
    "    \"#101892\": [[[137, 153], [69, 81], [106, 119]]],\n",
    "    \"#101990\": [[[101, 136], [75, 90], [72, 91]]],\n",
    "    \"#101991\": [[[98, 114], [83, 98], [105, 121]]],\n",
    "    \"#101995\": [[[114, 128], [64, 80], [95, 106]]],\n",
    "    \"#101998\": [[[107, 133], [75, 92], [95, 111]]],\n",
    "    \"#102024\": [[[66, 85], [58, 71], [93, 114]]],\n",
    "    \"#102084\": [[[38, 58], [76, 101], [92, 104]]],\n",
    "    \"#102141\": [[[96, 108], [79, 94], [110, 123]]],\n",
    "    \"#102158\": [[[149, 166], [79, 95], [99, 117]]],\n",
    "    \"#102200\": [[[101, 131], [82, 102], [72, 105]]],\n",
    "    \"#102201\": [[[106, 129], [77, 93], [90, 102]]],\n",
    "    \"#102202\": [[[95, 110], [71, 89], [103, 113]]],\n",
    "    \"#102228\": [[[149, 163], [82, 91], [99, 112]]],\n",
    "    \"#102283\": [[[169, 182], [76, 94], [90, 106]]],\n",
    "    \"#102333\": [[[104, 124], [82, 102], [90, 110]]],\n",
    "    \"#102348\": [[[71, 85], [74, 93], [90, 103]]],\n",
    "    \"#102391\": [[[118, 139], [66, 83], [100, 116]]],\n",
    "    \"#102418\": [[[117, 136], [66, 91], [86, 103]]],\n",
    "    \"#102427\": [[[68, 89], [87, 100], [81, 98]]],\n",
    "    \"#102442\": [[[67, 83], [67, 80], [92, 108]]],\n",
    "    \"#102455\": [[[144, 160], [71, 83], [84, 101]]],\n",
    "    \"#102496\": [[[160, 181], [74, 90], [100, 116]]],\n",
    "    \"#102564\": [[[116, 139], [70, 91], [106, 121]]],\n",
    "#    \"#102590\": [[[150, 164], [81, 90], [93, 109]],[[114,133],[78,92],[79,88]]],  # and [[118, 136], [82, 93], [77, 91]]\n",
    "#    \"#102595\": [[[112, 127], [70, 91], [83, 93]],[[113, 131], [75, 86], [92, 105]]],  # and [[113, 131], [75, 86], [92, 105]]\n",
    "    \"#102601\": [[[88, 104], [81, 96], [93, 104]]],\n",
    "    \"#102609\": [[[20, 42], [80, 98], [94, 115]]],\n",
    "    \"#102638\": [[[40, 60], [70, 86], [112, 130]]],\n",
    "    \"#102693\": [[[209, 125], [82, 98], [75, 92]]],\n",
    "    \"#102720\": [[[22, 36], [86, 100], [92, 103]]],\n",
    "    \"#102761\": [[[68, 85], [80, 94], [80, 98]]],\n",
    "    \"#102764\": [[[72, 91], [72, 92], [86, 97]]],\n",
    "    \"#102797\": [[[73, 86], [86, 102], [84, 98]]],\n",
    "    \"#102835\": [[[157, 178], [90, 104], [88, 101]]],\n",
    "    \"#102840\": [[[111, 129], [82, 94], [78, 94]]],\n",
    "  #  \"#102864\": [[[112, 132], [79, 100], [79, 93]],[[68, 88], [83, 97], [82, 95]],[[184, 201], [32, 48], [131, 143]]],  # and [[68, 88], [83, 97], [82, 95]], [[184, 201], [32, 48], [131, 143]]\n",
    "    \"#102886\": [[[41, 49], [71, 94], [97, 107]]],\n",
    "    \"#102935\": [[[143, 161], [71, 91], [104, 120]]],\n",
    "    \"#102959\": [[[66, 85], [78, 93], [90, 99]]],\n",
    "    \"#102974\": [[[110, 127], [76, 95], [71, 90]]]\n",
    "}\n",
    "\n",
    "\n",
    "converted_bboxes_with_comments = {}\n",
    "\n",
    "for key, bboxes in bounding_boxes_with_comments.items():\n",
    "    # Convert each list of bounding boxes or single bounding box\n",
    "    converted_bboxes_with_comments[key] = convert_bboxes(bboxes)\n",
    "\n",
    "print(converted_bboxes_with_comments)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f79b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train torch.Size([104, 1, 204, 204, 204])\n",
      "torch.Size([104, 8, 17, 17, 17]) TARGETS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/n49gt_b5117516rctl7_nsx40000gn/T/ipykernel_22010/3158519572.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [1/104], Loss: 0.21572944521903992\n",
      "Epoch [1/10], Batch [2/104], Loss: 0.1879815012216568\n",
      "Epoch [1/10], Batch [3/104], Loss: 0.16486185789108276\n",
      "Epoch [1/10], Batch [4/104], Loss: 0.1558379828929901\n",
      "Epoch [1/10], Batch [5/104], Loss: 0.15065714716911316\n",
      "Epoch [1/10], Batch [6/104], Loss: 0.14667336642742157\n",
      "Epoch [1/10], Batch [7/104], Loss: 0.14377611875534058\n",
      "Epoch [1/10], Batch [8/104], Loss: 0.14211443066596985\n",
      "Epoch [1/10], Batch [9/104], Loss: 0.1415337473154068\n",
      "Epoch [1/10], Batch [10/104], Loss: 0.14120949804782867\n",
      "Epoch [1/10], Batch [11/104], Loss: 0.1408495306968689\n",
      "Epoch [1/10], Batch [12/104], Loss: 0.14059139788150787\n",
      "Epoch [1/10], Batch [13/104], Loss: 0.14039114117622375\n",
      "Epoch [1/10], Batch [14/104], Loss: 0.1402612179517746\n",
      "Epoch [1/10], Batch [15/104], Loss: 0.14007072150707245\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m detections, predictions \u001b[38;5;241m=\u001b[39m model(input_data)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Apply sigmoid to the predictions\u001b[39;00m\n\u001b[1;32m    115\u001b[0m predictions_sigmoid \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(predictions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mResNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 75\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     76\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m     77\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    595\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    596\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    607\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nifti_directory = '/Users/lucabernecker/Desktop/N128_local/aneu_det'\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "# List all files in the folder\n",
    "file_ids = [key.strip(\"#\") for key in converted_bboxes_with_comments.keys()]\n",
    "\n",
    "# Initialize a list to store the loaded nifti images as numpy arrays\n",
    "nifti_images_list = []\n",
    "\n",
    "# Desired output shape\n",
    "desired_shape = (204, 204, 204)\n",
    "\n",
    "# Function to pad the images\n",
    "def pad_image(image, target_shape):\n",
    "    pad_width = [(0, max(0, t - s)) for s, t in zip(image.shape, target_shape)]\n",
    "    return np.pad(image, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "# Load and preprocess the nifti images\n",
    "for file_id in file_ids:\n",
    "    file_name = f\"cube_{file_id}.nii.gz\"\n",
    "    file_path = os.path.join(nifti_directory, file_name)\n",
    "    \n",
    "    # Load the nifti image\n",
    "    nifti_image = nib.load(file_path)\n",
    "    \n",
    "    # Convert the nifti image to a numpy array\n",
    "    image_data = nifti_image.get_fdata()\n",
    "    \n",
    "    # Pad the image to the desired shape\n",
    "    padded_image = pad_image(image_data, desired_shape)\n",
    "    \n",
    "    # Append to the list\n",
    "    nifti_images_list.append(padded_image)\n",
    "\n",
    "# Stack all numpy arrays into a single numpy array\n",
    "x_train = np.stack(nifti_images_list, axis=0)\n",
    "\n",
    "###############\n",
    "\n",
    "# Convert the list of images to a NumPy array\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_train = torch.unsqueeze(x_train, 1)\n",
    "print(\"X_Train\",np.shape(x_train))\n",
    "num_classes = 1\n",
    "\n",
    "grid_size = 17  # Grid size of 17x17x17\n",
    "targets = torch.zeros((104, 8, grid_size, grid_size, grid_size))  # Correctly sized target tensor\n",
    "\n",
    "# Sample data (example, use actual data for real case)\n",
    "\n",
    "data = converted_bboxes_with_comments\n",
    "# Calculate grid size\n",
    "cell_size = 204 / grid_size\n",
    "\n",
    "for sample_idx in range(targets.shape[0]):\n",
    "    for key, boxes in data.items():\n",
    "        for box in boxes:\n",
    "            x, y, z, w, h, d = box\n",
    "            \n",
    "            # Convert center coordinates to grid cell index\n",
    "            grid_x = int(x // cell_size)\n",
    "            grid_y = int(y // cell_size)\n",
    "            grid_z = int(z // cell_size)\n",
    "            \n",
    "            # Check if indices are within bounds\n",
    "            if grid_x >= grid_size or grid_y >= grid_size or grid_z >= grid_size:\n",
    "                continue\n",
    "            \n",
    "            # Normalize coordinates relative to the grid cell\n",
    "            x_offset = (x % cell_size) / cell_size\n",
    "            y_offset = (y % cell_size) / cell_size\n",
    "            z_offset = (z % cell_size) / cell_size\n",
    "            \n",
    "            # Normalize width, height, and depth relative to the input size\n",
    "            w_norm = w / 204\n",
    "            h_norm = h / 204\n",
    "            d_norm = d / 204\n",
    "            \n",
    "            # Fill in the targets\n",
    "            try:\n",
    "                targets[sample_idx, 0:3, grid_x, grid_y, grid_z] = torch.tensor([x_offset, y_offset, z_offset])\n",
    "                targets[sample_idx, 3:6, grid_x, grid_y, grid_z] = torch.tensor([w_norm, h_norm, d_norm])\n",
    "                targets[sample_idx, 6, grid_x, grid_y, grid_z] = 1  # Object confidence\n",
    "                targets[sample_idx, 7, grid_x, grid_y, grid_z] = 0  # Class target, assuming a single class\n",
    "            except IndexError as e:\n",
    "                print(f\"IndexError for box with center at ({x}, {y}, {z}) in sample {sample_idx}: {e}\")\n",
    "                continue\n",
    "num_epochs = 10\n",
    "batch_size = 1\n",
    "num_samples = x_train.shape[0]\n",
    "num_batches = int(np.ceil(num_samples / batch_size))\n",
    "        \n",
    "print(targets.shape,\"TARGETS\")\n",
    "def loss_fn(predictions, targets):\n",
    "    return torch.nn.functional.mse_loss(predictions, targets)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        input_data = x_train[start_idx:end_idx]\n",
    "        target_data = targets[start_idx:end_idx]\n",
    "        input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        detections, predictions = model(input_data)\n",
    "\n",
    "        # Apply sigmoid to the predictions\n",
    "        predictions_sigmoid = torch.sigmoid(predictions)\n",
    "\n",
    "        # Calculate loss using the custom loss function\n",
    "        loss = loss_fn(predictions_sigmoid, target_data)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss for this batch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{num_batches}], Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863526a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
